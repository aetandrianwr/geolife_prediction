# Recurrent Transformer Configuration
# Transformer-based recurrence: processes input sequence multiple times
# Hidden state refined at each cycle for better predictions

model:
  name: recurrent_transformer
  d_model: 96
  n_head: 8
  dim_feedforward: 192
  n_cycles: 3  # Number of recurrent cycles
  dropout: 0.1

training:
  batch_size: 64
  learning_rate: 0.0015  # Slightly higher for faster convergence
  weight_decay: 0.0001
  label_smoothing: 0.1
  max_epochs: 150
  patience: 25
  log_interval: 50
  warmup_epochs: 5
  grad_clip: 1.0

data:
  data_dir: /content/geolife_prediction/data/geolife
  max_len: 50
  num_workers: 0

experiment:
  name: recurrent_transformer
  seed: 42
  device: cuda
  checkpoint_dir: checkpoints
  log_dir: logs
  result_dir: results
  save_best_only: true
  deterministic: true
